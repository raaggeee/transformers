# Implementing Transformers from Scratch

## Encoder
### For Input
- [] Embeddings
- [] Positional Encoding
### For Encoder Layer
- [] Multihead Attention
- [] Feed Forward Neural Network
- [] Add and Normalize

## Decoder
### For Input
- [] Embeddings
- [] Positional Encoding
### For Decoder Layer
- [] Masked Multi Head Attention
- [] Cross Encoding
- [] Feed Forward Nerual Network
- [] Add and Normalize

## Reference https://medium.com/data-science/a-complete-guide-to-write-your-own-transformers-29e23f371ddd
